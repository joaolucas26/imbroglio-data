{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3584f683",
   "metadata": {},
   "source": [
    "Segue abaixo o nome, a abreviação e a descrição das 21 colunas de informações apresentadas\n",
    "nos resultados de uma pesquisa no Léxico do Português Brasileiro, versão Alfa.\n",
    "Ortografia (orto): forma ortográfica da palavra em letras minúsculas (com exceção dos\n",
    "nomes próprios), respeitando os acentos específicos de cada palavra37\n",
    ".\n",
    "- Categoria gramatical (cat_gram):<\n",
    "    - categorial gramatical da palavra (adj, adv, gram, nom,num, prop, ver).\n",
    "\n",
    "- Informação gramatical (inf_gram): \n",
    "    - informações gramaticais sobre a palavra (ex. singular/plural, masculino/feminino, passado/presente/futuro, 1/2/3 pessoas, etc.). \n",
    "- Frequência ortográfica (freq_orto): \n",
    "    - número de vezes que a palavra aparece no NILC (cerca de 32 milhões de palavras).\n",
    "\n",
    "- Frequência ortográfica por milhão (freq_orto/M): \n",
    "     - número de vezes que a palavra aparece entre 1 milhão de palavras. Valor padrão para frequência de palavras.\n",
    "\n",
    "- Logaritmo natural da frequência ortográfica (log10_freq_orto): \n",
    "    - logarítmico natural da frequência ortográfica. Os valores logarítmicos são utilizados para linearizar-se o comportamento das frequências das palavras no corpus.\n",
    "\n",
    "- Número de letras (nb_letras):\n",
    "    - número de letras da palavra.\n",
    "\n",
    "- Número de homógrafas (nb_homogr):\n",
    "    - número de palavras homógrafas. Palavras que possuem a mesma ortografia ou diferenças de acentos, mas pertencem a categorias gramaticais diferentes.\n",
    "\n",
    "- Homógrafas (homografas): \n",
    "     - categorias gramaticais das palavras homógrafas.\n",
    "\n",
    "- Ponto de unicidade ortográfico (pu_orto): \n",
    "    - letra a partir da qual a palavra se dissocia das outras, ou seja, letra a partir da qual a palavra é única. Sentido da esquerda para direita.\n",
    "\n",
    "- Vizinhos ortográficos (viz_orto): \n",
    "     - número de vizinhos ortográficos a partir do N de Coltheart, ou seja, alterando-se apenas uma letra por vez (Coltheart et al., 1977).\n",
    "\n",
    "- Distância de Leveinshtein ortográfica (old20):\n",
    "     - distância ortográfica de Leveinshtein das 20 palavras mais póximas calculadas a partir de regressões lineares (Yarkoni et al., 2008).\n",
    "\n",
    "- Estrutura CVCV (CVCV_orto):\n",
    "    - estrutura CVCV da palavra, onde consoantes são C e vogais são V. Ainda, A para acentos, P para pontuação, N para números e S para símbolos.\n",
    "\n",
    "- Bigramas (bigramas): \n",
    "    - bigramas que constituem a palavra separados por “_” e limitados por “#”. O número de bigramas é igual ao número de letras da palavra mais 1.\n",
    "\n",
    "- Trigramas (trigramas):\n",
    "     - trigramas que constituem a palavra separados por “_” e limitados por “#”. O número de trigramas é igual ao número de letras da palavra.\n",
    "\n",
    "- Ortografia invertida (inv_orto):\n",
    "    - forma invertida da ortografia (orto).\n",
    "\n",
    "- Estrutura CVCV invertida (inv_CVCV_orto):\n",
    "    - estrutura CVCV da palavra invertida a partir de (CVCV_orto).\n",
    "\n",
    "- Bigramas invertidos (inv_bigra): \n",
    "     - bigramas que constituem a palavra separados por “_” e limitados por “#” invertidos a partir de (bigramas).\n",
    "\n",
    "- Trigramas invertidos (inv_trigra):\n",
    "    - trigramas que constituem a palavra separados por “_” e limitados por “#” invertidos a partir de (trigramas).\n",
    "\n",
    "- Número aleatório entre 0 e 1 (aleatorio): \n",
    "    - número aleatório entre 0 e 1 com oito algarismos de precisão.\n",
    "\n",
    "- Número de identificação (id): \n",
    "    - número de identificação da palavra designado a partir da organização do corpus por frequência decrescente e ordem alfabética a-z. O número de identificação é a posição da palavra no corpus e no léxico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5068917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c06301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_palavrao(x):\n",
    "    if x not in palavroes:\n",
    "        return x\n",
    "    elif x not in norm_palavroes:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a882b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'lexporbr_alfa_excel.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lexico = pd.read_excel(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac492ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo o ARQUIVO DE PALAVROES \n",
    "f = open('Words/palavroes.txt') \n",
    "palavroes = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d382baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavroes = pd.Series(palavroes).apply(lambda x: x.lower().replace('\\n ', '').replace(' ', ''))\n",
    "norm_palavroes = pd.Series(palavroes).apply(lambda row: strip_accents(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexico_filtered = df_lexico[(df_lexico['nb_letras'] > 2) & (df_lexico['nb_letras'] <= 6) & (df_lexico['cat_gram'] == 'nom')].sort_values(by='freq_orto/M', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda0adf",
   "metadata": {},
   "source": [
    "### Verifica e retira palavras escolhidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexico_filtered.ortografia = lexico_filtered['ortografia'].apply(lambda row: verifica_palavrao(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f484a0",
   "metadata": {},
   "source": [
    "### tratar toda a base para tirar palavras com hifen, ponto, caracteres especiais, numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratativa(X):  \n",
    "    '''\n",
    "    Entrada: series\n",
    "    X_norm \n",
    "        - retira acentos das palavras \n",
    " \n",
    "    list comprehension\n",
    "        - remove palavras com hifen\n",
    "        - remove \".\"\n",
    "        - remove palavra com menos de 2 caracter\n",
    "        - remove palavras com letras maisculas (nomes proprios)\n",
    "        - remove palavras com caracteres especiais utilizando regex\n",
    "        - retira palavras escolhidas\n",
    "        \n",
    "    return: 2 listas, 1 de palavras sem acentos e outra normal\n",
    "    '''\n",
    "    \n",
    "    #verificacao do regex para caracteres especiais\n",
    "    string_check = re.compile(\"['-@_!#$%^&*()<>?/\\|}{~:¹²³£¢¬ªº°]\")\n",
    "\n",
    "    word_list = [x for x in X\n",
    "                if  '-' not in x \n",
    "                and string_check.search(x) == None\n",
    "                and len(x) > 2 \n",
    "                and '.' not in x \n",
    "                and x.lower() == x\n",
    "                ]\n",
    "    \n",
    "    \n",
    "    # removendo acentos\n",
    "    y = pd.Series(word_list)\n",
    "    X_norm = y.apply(lambda row: strip_accents(row))\n",
    "\n",
    "    print(\"len lista palavras normalizadas: \", len(X_norm))\n",
    "    print(\"len lista palavras : \", len(word_list))\n",
    "\n",
    "    \n",
    "    return X_norm.to_list(), word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word_list, word_list= tratativa(lexico_filtered.head(1200)['ortografia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be46e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdaa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4531d292",
   "metadata": {},
   "source": [
    "### Criando Dataframe com os puzzles diarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_puzzles(normalized_word_list, word_list):\n",
    "    \n",
    "    a = datetime.datetime(2022, 3, 11)\n",
    "\n",
    "    numdays = 365\n",
    "    dateList = []\n",
    "    for x in range (0, numdays):\n",
    "        dateList.append(a + datetime.timedelta(days = x))\n",
    "\n",
    "\n",
    "    dic = {'norm_word': normalized_word_list,\n",
    "           'word': word_list}\n",
    "\n",
    "    word_df = pd.DataFrame(dic, columns=['norm_word', 'word'])\n",
    "\n",
    "\n",
    "\n",
    "    df_puzzle_day = pd.DataFrame(dateList, columns=['date']) # cria um dataframe com todas as datas para agrupamento\n",
    "\n",
    "    # cria colunas que serão utilizadas no dataframe\n",
    "    df_puzzle_day['day_puzzle'] = 0\n",
    "    df_puzzle_day['day_puzzle_norm'] =  0\n",
    "    df_puzzle_day['letters'] = 0\n",
    "    df_puzzle_day['letters_norm'] = 0\n",
    "    df_puzzle_day['word_letters_list'] = 0\n",
    "    df_puzzle_day['word_letters_list_norm'] = 0\n",
    "\n",
    "\n",
    "    #loop que varre todas as datas enumerando-as\n",
    "    for index, date in enumerate(dateList):\n",
    "        sample = word_df.sample(3, random_state=index) # pega o sample da base de lista utilizando como random state o index do df, para futuras consultas\n",
    "        day_puzzle = sample.word.tolist() # transforma as 3 palavras selecionadas do sample em uma lista\n",
    "        day_puzzle_norm = sample.norm_word.tolist() # transforma as 3 palavras selecionadas do sample em uma lista\n",
    "\n",
    "\n",
    "        # Seleciona as letras das palavras selecionadas em uma listas 3 (uma para cada palavra)\n",
    "        day_puzzle_letters = []\n",
    "        for word in day_puzzle:\n",
    "            day_puzzle_letters.append(sorted(word))\n",
    "\n",
    "        # transforma a lista de listas em uma unica lista, ordendando as letras\n",
    "        flat_letter_list = sorted([item for sublist in day_puzzle_letters for item in sublist])\n",
    "\n",
    "        day_puzzle_letters_norm = []\n",
    "        for word in day_puzzle_norm:\n",
    "            day_puzzle_letters_norm.append(sorted(word))\n",
    "\n",
    "        # transforma a lista de listas em uma unica lista, ordendando as letras\n",
    "        flat_letter_list_norm = sorted([item for sublist in day_puzzle_letters_norm for item in sublist])\n",
    "\n",
    "\n",
    "        #atribui os dados obtidos no looping para o dataframe\n",
    "        df_puzzle_day['date'][index] = date.date()\n",
    "        df_puzzle_day['day_puzzle'][index] =  day_puzzle\n",
    "        df_puzzle_day['day_puzzle_norm'][index] =  day_puzzle_norm\n",
    "        df_puzzle_day['letters'][index] = flat_letter_list\n",
    "        df_puzzle_day['letters_norm'][index] = flat_letter_list_norm\n",
    "        df_puzzle_day['word_letters_list'][index] = day_puzzle_letters\n",
    "        df_puzzle_day['word_letters_list_norm'][index] = day_puzzle_letters_norm\n",
    "\n",
    "        \n",
    "    return df_puzzle_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puzzle_day = df_puzzles(normalized_word_list, word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc41c2",
   "metadata": {},
   "source": [
    "## CRIANDO O JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "dic_aux = {}\n",
    "list = []\n",
    "\n",
    "\n",
    "for date, letter_norm, solution in zip(df_puzzle_day.date, df_puzzle_day.letters_norm, df_puzzle_day.day_puzzle):\n",
    "    dic_aux = {\n",
    "        'id': i,\n",
    "        'date':str(date),\n",
    "        'letters': letter_norm,\n",
    "        'solution': solution\n",
    "    }    \n",
    "    list.append(dic_aux)\n",
    "    i = i+1\n",
    "    \n",
    "# #salvando o arquivo json\n",
    "# with open('Puzzles/daily_puzzles_6.json', 'w') as f:\n",
    "#     json.dump(list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79388856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7332609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo o JSON \n",
    "f = open('Puzzles/daily_puzzles_6.json') \n",
    "daily_puzzles = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f5ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c5779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603fe76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
