{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065b89e5",
   "metadata": {},
   "source": [
    " Este notebook tem por função remover algumas palavras da lista de palavras em produção.\n",
    "o objetivo é ler a lista utilizada, e atraves de uma lista de palavras \"banidas\" remover elas da lista de verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609a6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a74a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo o JSON \n",
    "f = open('Data/words.json') \n",
    "words_file = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a8973d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>norm_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>para</td>\n",
       "      <td>para</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>não</td>\n",
       "      <td>nao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uma</td>\n",
       "      <td>uma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>por</td>\n",
       "      <td>por</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dos</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>como</td>\n",
       "      <td>como</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mais</td>\n",
       "      <td>mais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>foi</td>\n",
       "      <td>foi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word norm_word\n",
       "0   que       que\n",
       "1  para      para\n",
       "2   com       com\n",
       "3   não       nao\n",
       "4   uma       uma\n",
       "5   por       por\n",
       "6   dos       dos\n",
       "7  como      como\n",
       "8  mais      mais\n",
       "9   foi       foi"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformando o sjson em um df\n",
    "word_list = []\n",
    "normalized_word_list =[]\n",
    "\n",
    "for dic in words_file:\n",
    "    word_list.append(dic['word'])\n",
    "    normalized_word_list.append(dic['normalized'])\n",
    "    \n",
    "dic = {'word': word_list,\n",
    "      'norm_word': normalized_word_list}\n",
    "\n",
    "words_df = pd.DataFrame(dic, columns =['word', 'norm_word'])\n",
    "words_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0a2aa",
   "metadata": {},
   "source": [
    "# lista de palavras a se retirar do json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e701b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "retirar = ['podecontinuar',\n",
    "           'ypodo', \n",
    "           'yorker',\n",
    "           'ÿpoder',\n",
    "           'zagueir',\n",
    "           'zanjar',\n",
    "           'zepter',\n",
    "           'wagnerizar',\n",
    "           'welcher',\n",
    "           'wieder',\n",
    "           'workwear',\n",
    "           'writter',\n",
    "           'yorker',\n",
    "           'ÿpoder',\n",
    "           'deveser',\n",
    "           'deavalorizou',\n",
    "           'evt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34bdfa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 93242, 112539, 115758, 121375, 154163, 154191, 154208, 154227,\n",
       "            154232, 154368, 154371, 154390, 154410, 154471],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = words_df[words_df.word.isin(retirar)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82142bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words_df = words_df.drop(indexes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883b3da",
   "metadata": {},
   "source": [
    "#  Tranformando novamente no json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f664b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "dic_aux = {}\n",
    "list_aux = []\n",
    "\n",
    "for word, norm_word in zip(new_words_df['word'], new_words_df['norm_word']):\n",
    "    dic_aux = {\n",
    "        'id': i,\n",
    "        'word':word,\n",
    "        'normalized': norm_word\n",
    "    }    \n",
    "    list_aux.append(dic_aux)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17b6707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando o arquivo json\n",
    "#with open('Data/words.json', 'w') as f:\n",
    "#     json.dump(list_aux, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96069374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
